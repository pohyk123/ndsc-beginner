{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Non-CS .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "VDkfJhTszS0n",
        "BkxvOnUlzcmX",
        "TBkqe-B8zqYQ",
        "3PD4liMs0A92",
        "oJzHpV7T0NqR",
        "dynLSKwP0m_s",
        "mVrueLre0qsr",
        "Jo7iDsaq2Do-",
        "m2zgUh3H1vq7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "VDkfJhTszS0n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download raw images provided by NDSC"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tJEf6d_el9A2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir /content/images/\n",
        "!wget https://www.dropbox.com/s/bhy4b7bwsvvhtf6/beauty_image.tar.gz?dl=0\n",
        "!tar -zxf beauty_image.tar.gz?dl=0 -C /content/images/ --strip-components=1\n",
        "!wget https://www.dropbox.com/s/ss2ibxu0k4x9c91/mobile_image.tar.gz?dl=0\n",
        "!tar -zxf mobile_image.tar.gz?dl=0 -C /content/images/ --strip-components=1\n",
        "!wget https://www.dropbox.com/s/3jpwfbeilm22vhs/fashion_image.tar.gz?dl=0\n",
        "!tar -zxf fashion_image.tar.gz?dl=0 -C /content/images/ --strip-components=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BkxvOnUlzcmX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "metadata": {
        "id": "NmjF3l7-zQ0Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.utils import to_categorical, Sequence, plot_model\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.models import load_model, Model, Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input, Concatenate, concatenate\n",
        "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
        "from IPython.display import SVG\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TBkqe-B8zqYQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up file paths & import other provided data"
      ]
    },
    {
      "metadata": {
        "id": "hvbmgZoJzpiF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "base_folder = '/content/gdrive/My Drive/NDSC/'\n",
        "data_folder = base_folder + 'data/'\n",
        "train_data_filepath = data_folder + 'train_jpg.csv'\n",
        "test_data_filepath = data_folder + 'test.csv'\n",
        "predict_folder = base_folder + 'predict/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ZE5GjVwNmbu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Read categories.json\n",
        "with open(data_folder+'categories.json') as f:\n",
        "    categories = json.load(f)\n",
        "    \n",
        "# Create categories dictionary with numbers as keys and major/minor categories as values\n",
        "cat = {}\n",
        "for major,minors in categories.items():\n",
        "    for minor,val in minors.items():\n",
        "      cat[val] = (major,minor)\n",
        "    \n",
        "print('Categories: \\n{}'.format(cat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHe1X0kDBBDo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import train data\n",
        "df = pd.read_csv(train_data_filepath)\n",
        "df = df.sample(frac=1,random_state=7).reset_index(drop=True)\n",
        "df['true_path'] =  ['/content/images/'+ (img.split('/')[1]) for img in df['image_path']]\n",
        "\n",
        "df_test = pd.read_csv(test_data_filepath)\n",
        "df_test['true_path'] =  ['/content/images/'+ (img.split('/')[1]) for img in df_test['image_path']]\n",
        "\n",
        "# OHE labels\n",
        "Y_train = to_categorical(df['Category'])\n",
        "hist = plt.hist(np.argmax(Y_train,axis=1),bins=58,range=[-0.5,57.5]) # visualise distribution\n",
        "\n",
        "m = df.shape[0]\n",
        "n = np.unique(np.argmax(Y_train,axis=1)).shape[0]\n",
        "print('No. of images:',m)\n",
        "print('Number of categories:',n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3PD4liMs0A92",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Quick data exploration/visualisation"
      ]
    },
    {
      "metadata": {
        "id": "u1Jb-TTkz-RY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_files = glob.glob('/content/images/*')\n",
        "print('A total of {} images have been downloaded.'.format(len(image_files)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lACP_SCv4I5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Show you 5 random images\n",
        "im5 = df.sample(n=5)\n",
        "fig = plt.figure(figsize=(25,125))\n",
        "for i in range(5):\n",
        "  im = image.load_img(im5['true_path'].iloc[i],target_size=(224,224))\n",
        "  print('Image: ',cat[im5['Category'].iloc[i]],im5['title'].iloc[i])\n",
        "  fig.add_subplot(1,5,i+1)\n",
        "  plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJzHpV7T0NqR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "lYHn_DSqbddS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate word bank and encode\n",
        "print('Encoding all title words...')\n",
        "# Create list of all titles\n",
        "titles = list(df['title'])\n",
        "titles = [title.split() for title in titles]\n",
        "titles_test = list(df_test['title'])\n",
        "titles_test = [title.split() for title in titles_test]\n",
        "\n",
        "# OHE for title words (aka unique word bank)\n",
        "mlb = MultiLabelBinarizer(sparse_output=True)\n",
        "titles_enc = mlb.fit_transform(titles)\n",
        "titles_test_enc = mlb.transform(titles_test)\n",
        "N_dict = len(mlb.classes_)\n",
        "print('Encoding complete. # unique words:',N_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dynLSKwP0m_s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create/Load Model"
      ]
    },
    {
      "metadata": {
        "id": "Qb_-v6YwsUw8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use this if loading a trained model instead\n",
        "model = load_model(base_folder+'models/model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZBU3MDFOSlt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "# input data conists of a list, first containing an image and second the title tags\n",
        "\n",
        "print('Generating model...')\n",
        "input_layer_word = Input(shape=(N_dict,))\n",
        "input_layer_conv = Input(shape=(224,224,3))\n",
        "base_model = ResNet50(weights='imagenet',include_top=False,input_tensor=input_layer_conv)\n",
        "x_img = base_model.output\n",
        "x_img = GlobalAveragePooling2D()(x_img)\n",
        "x_img = Dense(512, activation='relu')(x_img)\n",
        "x_img = Dropout(0.3)(x_img)\n",
        "x_word = Dense(2048,activation='relu')(input_layer_word)\n",
        "## new dropout layer\n",
        "# x_word = Dropout(0.3)(x_word)\n",
        "\n",
        "x = concatenate([x_img,x_word])\n",
        "x = Dense(58, activation='relu')(x)\n",
        "predictions = Dense(58, activation='softmax')(x)\n",
        "\n",
        "# freeze all convolutional imagenet layers\n",
        "for layer in base_model.layers:\n",
        "    print(layer.name)\n",
        "    layer.trainable = False\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=[input_layer_conv,input_layer_word], outputs=predictions)\n",
        "model.summary()\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mVrueLre0qsr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train & Evaluate Model"
      ]
    },
    {
      "metadata": {
        "id": "qimKgb4rLREv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fit Generator\n",
        "class My_Generator(Sequence):\n",
        "\n",
        "    def __init__(self, input_data, labels, batch_size):\n",
        "        [self.image_filenames, self.titles], self.labels = input_data, labels\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x_titles = np.array(self.titles[idx * self.batch_size:(idx + 1) * self.batch_size].todense())\n",
        "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "  \n",
        "        batch_x_image = []\n",
        "        for item in batch_x:\n",
        "          img = image.load_img(item, target_size=(224, 224))\n",
        "          batch_x_image.append(image.img_to_array(img))\n",
        "          \n",
        "        batch_x_image = np.array(batch_x_image)\n",
        "        batch_x_image = preprocess_input(batch_x_image)\n",
        "        \n",
        "        return [batch_x_image,batch_x_titles],np.array(batch_y)\n",
        "      \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "split_ratio = 0.95\n",
        "divide = int(split_ratio*m)\n",
        "batch_size = 64\n",
        "num_epochs = 1\n",
        "\n",
        "# convert data into valid numpy format\n",
        "true_path_np = np.array(df['true_path'])\n",
        "                     \n",
        "\n",
        "training_filenames,validation_filenames = [true_path_np[:divide],titles_enc[:divide]],[true_path_np[divide:],titles_enc[divide:]]\n",
        "GT_training,GT_validation = Y_train[:divide],Y_train[divide:]\n",
        "\n",
        "my_training_batch_generator = My_Generator(training_filenames, GT_training, batch_size)\n",
        "my_validation_batch_generator = My_Generator(validation_filenames, GT_validation, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9dhvKbuKsNlE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "print('Training in progres...')\n",
        "history = model.fit_generator(generator=my_training_batch_generator,\n",
        "                                          steps_per_epoch=(m // batch_size),\n",
        "                                          epochs=num_epochs,\n",
        "                                          verbose=1,\n",
        "                                          validation_data=my_validation_batch_generator,\n",
        "                                          validation_steps=(m // batch_size),\n",
        "                                          use_multiprocessing=False,\n",
        "                                          workers=16,\n",
        "                                          max_queue_size=32)\n",
        "\n",
        "# Save trained model\n",
        "model.save(base_folder+'models/ultimate_v2_4epochs.h5')\n",
        "\n",
        "# Evaluate\n",
        "scores = model.evaluate_generator(generator=my_validation_batch_generator, verbose = 1)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NTWV-ORxbeZQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(base_folder+'models/new_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jo7iDsaq2Do-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualise loss history"
      ]
    },
    {
      "metadata": {
        "id": "rLWxBrVw2ClG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2zgUh3H1vq7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict test set for submission"
      ]
    },
    {
      "metadata": {
        "id": "TOK5TCY1t8OU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Predict_Generator(Sequence):\n",
        "\n",
        "    def __init__(self, input_data, batch_size):\n",
        "        self.image_filenames, self.titles = input_data\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x_titles = np.array(self.titles[idx * self.batch_size:(idx + 1) * self.batch_size].todense())\n",
        "  \n",
        "        batch_x_image = []\n",
        "        for item in batch_x:\n",
        "          img = image.load_img(item, target_size=(224, 224))\n",
        "          batch_x_image.append(image.img_to_array(img))\n",
        "          \n",
        "        batch_x_image = np.array(batch_x_image)\n",
        "        batch_x_image = preprocess_input(batch_x_image)\n",
        "        \n",
        "        return [batch_x_image,batch_x_titles]\n",
        "\n",
        "# convert data into valid numpy format\n",
        "true_path_np_test = np.array(df_test['true_path'])\n",
        "batch_size = 256\n",
        "\n",
        "my_prediction_batch_generator = Predict_Generator([true_path_np_test,titles_test_enc], batch_size)\n",
        "      \n",
        "# Generate predictions\n",
        "predictions = model.predict_generator(my_prediction_batch_generator,verbose=1)\n",
        "\n",
        "# Save to csv\n",
        "predictions = np.argmax(predictions,axis=1)\n",
        "output_file = predict_folder + 'ult_v2_2epochs.csv'\n",
        "  \n",
        "output = pd.DataFrame({'itemid':df_test['itemid'],'Category':predictions})\n",
        "output.to_csv(output_file,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}